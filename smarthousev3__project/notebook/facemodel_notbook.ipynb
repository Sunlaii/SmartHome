{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl5NdXyA5vcd"
      },
      "source": [
        "#LOAD DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9iAfYq6QqxK1",
        "outputId": "2b81f66f-7848-455c-9ba8-9e715156ab2c"
      },
      "outputs": [],
      "source": [
        "pip install kagglehub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPiMTJBSq9pL",
        "outputId": "f309a644-967a-4b53-d2b9-3c181584573b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/hearfool/vggface2?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2.32G/2.32G [01:23<00:00, 29.7MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset được tải về tại: /root/.cache/kagglehub/datasets/hearfool/vggface2/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Tải dataset VGGFace2 từ Kaggle\n",
        "dataset_path = kagglehub.dataset_download(\"hearfool/vggface2\")\n",
        "\n",
        "print(\"Dataset được tải về tại:\", dataset_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6WdtCCr7zYE"
      },
      "source": [
        "* 3.Kết nối vs Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuLL6Y454Yy9",
        "outputId": "2acd138d-8a3f-4a06-b554-d85d33801ea2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xLc2mRh78CU"
      },
      "source": [
        "* lấy 93 thư mục"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rboHbpYNhuJ9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import kagglehub\n",
        "\n",
        "# Tải dataset VGGFace2 từ Kaggle\n",
        "dataset_path = \"/root/.cache/kagglehub/datasets/hearfool/vggface2/versions/1/train\"\n",
        "\n",
        "# Lấy danh sách tất cả thư mục con (danh tính)\n",
        "all_folders = [f for f in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, f))]\n",
        "\n",
        "# Sắp xếp thư mục theo tên\n",
        "all_folders.sort()\n",
        "\n",
        "selected_folders = all_folders[0:93]\n",
        "\n",
        "\n",
        "for folder in all_folders:\n",
        "    if folder not in selected_folders:\n",
        "        shutil.rmtree(os.path.join(dataset_path, folder))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "078yBsWT-37S"
      },
      "source": [
        "#Khai báo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uv6DNCh9rqE8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from mtcnn import MTCNN\n",
        "from tqdm import tqdm\n",
        "from facenet_pytorch import MTCNN\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ESgsfoTr0ZWN",
        "outputId": "78153161-7e6f-4eda-926a-8c4e1d5c439a"
      },
      "outputs": [],
      "source": [
        "pip install facenet-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wLFRkUBDsBsJ",
        "outputId": "869aa547-e542-47ec-b0e8-e15f5f9aa187"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mtcnn\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn) (1.4.2)\n",
            "Collecting lz4>=4.3.3 (from mtcnn)\n",
            "  Downloading lz4-4.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Downloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lz4, mtcnn\n",
            "Successfully installed lz4-4.4.3 mtcnn-1.0.0\n"
          ]
        }
      ],
      "source": [
        "pip  install mtcnn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpT7eeWer0ZN"
      },
      "source": [
        "#2.Tiền Xử lí"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8rpbVtarnyd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Định nghĩa đường dẫn dữ liệu\n",
        "input_folder = \"/root/.cache/kagglehub/datasets/hearfool/vggface2/versions/1/train\"\n",
        "output_folder = \"/content/drive/My Drive/Processed_Images\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Khởi tạo MTCNN để phát hiện khuôn mặt\n",
        "detector = MTCNN(keep_all=False, device=device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kd2ejQ9FrvpY"
      },
      "outputs": [],
      "source": [
        "def process_image(image_path, output_path):\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    # Kiểm tra xem ảnh có được đọc thành công hay không\n",
        "    if img is None:\n",
        "        return  # Bỏ qua ảnh nếu không đọc được\n",
        "\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Chuyển ảnh sang RGB\n",
        "    faces, _ = detector.detect(img_rgb, landmarks=False)\n",
        "\n",
        "    # Kiểm tra nếu `faces` là None hoặc không có khuôn mặt nào\n",
        "    if faces is None or len(faces) == 0:\n",
        "        return\n",
        "\n",
        "\n",
        "\n",
        "    x, y, w, h = map(int, faces[0])  # Chuyển tọa độ về số nguyên\n",
        "    h_img, w_img, _ = img_rgb.shape  # Lấy kích thước ảnh\n",
        "    if x < 0 or y < 0 or x + w > w_img or y + h > h_img:\n",
        "      return  # Bỏ qua ảnh lỗi\n",
        "\n",
        "    face = img_rgb[y:y+h, x:x+w]  # Cắt ảnh khuôn mặt từ ảnh gốc\n",
        "    face_resized = cv2.resize(face, (160, 160))  # Resize về 112x112\n",
        "    # print(f\"đã lưu:{image_path}\"\n",
        "    Image.fromarray(face_resized).save(output_path)  # Lưu ảnh đã xử lý\n",
        "    # print(f\"đã lưu:{image_path}\")\n",
        "\n",
        "\n",
        "# Lặp qua từng ảnh trong dataset\n",
        "for person in tqdm(os.listdir(input_folder)):\n",
        "    person_folder = os.path.join(input_folder, person)\n",
        "    output_person_folder = os.path.join(output_folder, person)\n",
        "    os.makedirs(output_person_folder, exist_ok=True)\n",
        "\n",
        "    for img_name in os.listdir(person_folder):\n",
        "        img_path = os.path.join(person_folder, img_name)\n",
        "        output_path = os.path.join(output_person_folder, img_name)\n",
        "        process_image(img_path, output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6l7DNHrUQBC",
        "outputId": "6afb1ab9-a0d7-4861-e517-ebb2085e0b18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tổng số ảnh trong thư mục: 1860\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def count_images(folder_path, extensions=['.jpg', '.png', '.jpeg']):\n",
        "    count = 0\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        count += sum(1 for file in files if any(file.lower().endswith(ext) for ext in extensions))\n",
        "    return count\n",
        "\n",
        "# Thay đổi đường dẫn thành thư mục cần kiểm tra\n",
        "folder_path = \"/content/drive/My Drive/Processed_Images\"\n",
        "total_images = count_images(folder_path)\n",
        "\n",
        "print(f\"Tổng số ảnh trong thư mục: {total_images}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmRI-QAf2y8m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "# Thay đường dẫn bằng đường dẫn thư mục chứa các thư mục con\n",
        "main_dir = \"/content/drive/My Drive/Processed_Images\"\n",
        "\n",
        "def reduce_images_in_folders(main_dir, max_images=25):\n",
        "    for subdir in os.listdir(main_dir):\n",
        "        subdir_path = os.path.join(main_dir, subdir)\n",
        "\n",
        "        if os.path.isdir(subdir_path):  # Kiểm tra nếu là thư mục\n",
        "            images = [f for f in os.listdir(subdir_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "            if len(images) > max_images:\n",
        "                images_to_remove = random.sample(images, len(images) - max_images)  # Chọn ảnh để xóa\n",
        "\n",
        "                for img in images_to_remove:\n",
        "                    img_path = os.path.join(subdir_path, img)\n",
        "                    os.remove(img_path)\n",
        "\n",
        "                print(f\"Đã giảm thư mục {subdir} còn {max_images} ảnh.\")\n",
        "\n",
        "reduce_images_in_folders(main_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OsdeknPr6gO"
      },
      "source": [
        "#3.Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sX5q-MIgwXcu"
      },
      "outputs": [],
      "source": [
        "pip install torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yYUe_aH1r90H",
        "outputId": "0e025717-808c-49f3-cfd8-a0a27a8deea0"
      },
      "outputs": [],
      "source": [
        "pip install torch torchvision facenet-pytorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GQe-nIuyy-a"
      },
      "source": [
        "#Chia dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7csSx_YzMMS",
        "outputId": "282baadb-2e61-43bf-aedc-046ec5450390"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Dataset đã được chia thành train/val.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "def split_dataset(original_dir, output_dir, train_ratio=0.8):\n",
        "    # Tạo folder output\n",
        "    train_dir = os.path.join(output_dir, 'train')\n",
        "    val_dir = os.path.join(output_dir, 'val')\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "    # Duyệt từng class (người)\n",
        "    for person in os.listdir(original_dir):\n",
        "        person_dir = os.path.join(original_dir, person)\n",
        "        if not os.path.isdir(person_dir):\n",
        "            continue\n",
        "\n",
        "        images = os.listdir(person_dir)\n",
        "        random.shuffle(images)\n",
        "        split_idx = int(len(images) * train_ratio)\n",
        "\n",
        "        train_images = images[:split_idx]\n",
        "        val_images = images[split_idx:]\n",
        "\n",
        "        # Tạo thư mục class trong train/val\n",
        "        os.makedirs(os.path.join(train_dir, person), exist_ok=True)\n",
        "        os.makedirs(os.path.join(val_dir, person), exist_ok=True)\n",
        "\n",
        "        # Copy ảnh vào thư mục mới\n",
        "        for img in train_images:\n",
        "            src = os.path.join(person_dir, img)\n",
        "            dst = os.path.join(train_dir, person, img)\n",
        "            shutil.copy2(src, dst)\n",
        "\n",
        "        for img in val_images:\n",
        "            src = os.path.join(person_dir, img)\n",
        "            dst = os.path.join(val_dir, person, img)\n",
        "            shutil.copy2(src, dst)\n",
        "\n",
        "    print(\"✅ Dataset đã được chia thành train/val.\")\n",
        "\n",
        "# Gọi hàm\n",
        "original_dataset = \"/content/drive/My Drive/Processed_Images\"\n",
        "output_dataset = \"/content/drive/My Drive/Split_Images\"\n",
        "split_dataset(original_dataset, output_dataset, train_ratio=0.8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5muRtJQz0eb"
      },
      "source": [
        "#Định nghĩa trip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bIbDkzpzxID"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TripletFaceDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform):\n",
        "        self.transform = transform\n",
        "        self.classes = os.listdir(root_dir)\n",
        "        self.class_to_images = {}\n",
        "\n",
        "        for cls in self.classes:\n",
        "            cls_path = os.path.join(root_dir, cls)\n",
        "            if not os.path.isdir(cls_path): continue\n",
        "\n",
        "            images = [os.path.join(cls_path, img) for img in os.listdir(cls_path)]\n",
        "            if len(images) >= 2:\n",
        "                self.class_to_images[cls] = images\n",
        "\n",
        "        self.classes = list(self.class_to_images.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return 10000  # Số lượng sample lấy ngẫu nhiên\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        import random\n",
        "        anchor_class = random.choice(self.classes)\n",
        "        positive_class = anchor_class\n",
        "        negative_class = random.choice([c for c in self.classes if c != anchor_class])\n",
        "\n",
        "        anchor_path, positive_path = random.sample(self.class_to_images[anchor_class], 2)\n",
        "        negative_path = random.choice(self.class_to_images[negative_class])\n",
        "\n",
        "        anchor = self.transform(Image.open(anchor_path).convert(\"RGB\"))\n",
        "        positive = self.transform(Image.open(positive_path).convert(\"RGB\"))\n",
        "        negative = self.transform(Image.open(negative_path).convert(\"RGB\"))\n",
        "\n",
        "        return anchor, positive, negative\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMwnF70az44Y"
      },
      "source": [
        "#load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbVpVLPqz6Mj",
        "outputId": "6aa257de-fff6-432f-b3d8-de6adb0bcbad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((112, 112)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# Load train và val\n",
        "train_dataset = TripletFaceDataset(\"/content/drive/My Drive/Split_Images/train\", transform)\n",
        "val_dataset = TripletFaceDataset(\"/content/drive/My Drive/Split_Images/val\", transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Model\n",
        "model = models.resnet50(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 512)\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss và Optimizer\n",
        "criterion = nn.TripletMarginLoss(margin=1.0, p=2)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esr_m1lxz8o1"
      },
      "source": [
        "#train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S_V5ty50AwN",
        "outputId": "4a71ad66-37e7-416b-8b26-38a864764ca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Train Loss: 108.5397\n",
            "Epoch [2/10], Train Loss: 44.2910\n",
            "Epoch [3/10], Train Loss: 29.8469\n",
            "Epoch [4/10], Train Loss: 24.5080\n",
            "Epoch [5/10], Train Loss: 20.4178\n",
            "Epoch [6/10], Train Loss: 14.2874\n",
            "Epoch [7/10], Train Loss: 12.8980\n",
            "Epoch [8/10], Train Loss: 15.9484\n",
            "Epoch [9/10], Train Loss: 15.8148\n",
            "Epoch [10/10], Train Loss: 15.4021\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for anchor, positive, negative in train_loader:\n",
        "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        anchor_out = model(anchor)\n",
        "        positive_out = model(positive)\n",
        "        negative_out = model(negative)\n",
        "\n",
        "        loss = criterion(anchor_out, positive_out, negative_out)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {total_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaBi45Aq0l4n"
      },
      "source": [
        "#Lưu model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44aB2N-x0oVS",
        "outputId": "c45843c0-333e-4050-ca9b-f407847da998"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Đã lưu model trích xuất đặc trưng.\n"
          ]
        }
      ],
      "source": [
        "torch.save(model, \"face_model_feature_v3.pth\")\n",
        "print(\"✅ Đã lưu model trích xuất đặc trưng.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtmk7GJq7Uqa"
      },
      "source": [
        "#Đánh giá"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqoSDzxqEfNq"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    cosine_similarities_pos = []\n",
        "    cosine_similarities_neg = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for anchor, positive, negative in val_loader:\n",
        "            anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
        "\n",
        "            anchor_out = model(anchor)\n",
        "            positive_out = model(positive)\n",
        "            negative_out = model(negative)\n",
        "\n",
        "            # Cosine similarity\n",
        "            sim_pos = F.cosine_similarity(anchor_out, positive_out)\n",
        "            sim_neg = F.cosine_similarity(anchor_out, negative_out)\n",
        "\n",
        "            # Đánh giá: nếu sim_pos > sim_neg => đúng\n",
        "            correct += torch.sum(sim_pos > sim_neg).item()\n",
        "            total += anchor.size(0)\n",
        "\n",
        "            cosine_similarities_pos.extend(sim_pos.cpu().numpy())\n",
        "            cosine_similarities_neg.extend(sim_neg.cpu().numpy())\n",
        "\n",
        "    accuracy = correct / total * 100\n",
        "    print(f\"✅ Độ chính xác trên val set: {accuracy:.2f}%\")\n",
        "    return cosine_similarities_pos, cosine_similarities_neg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9hW4e0cEmwB",
        "outputId": "fcbe730d-451b-4a38-a95c-ce4b089d932f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Độ chính xác trên val set: 90.50%\n"
          ]
        }
      ],
      "source": [
        "# Load lại model nếu cần\n",
        "model = torch.load(\"face_model_feature_v3.pth\", weights_only=False)\n",
        "model.eval()\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Đánh giá trên val_loader\n",
        "cosine_pos, cosine_neg = evaluate(model, val_loader)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
